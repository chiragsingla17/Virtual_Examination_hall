# Virtual_Examination_hall
Run all code in code folder 
Project to create an automated proctoring system where the user can be monitored automatically through the webcam and microphone. The project is divided into two parts: vision and audio based functionalities.

# Vision
It has six vision based functionalities right now:

1. Track eyeballs and report if candidate is looking left, right or up.
2. Find if the candidate opens his mouth by recording the distance between lips at starting.
3. Instance segmentation to count number of people and report if no one or more than one person detected.
4. Find and report any instances of mobile phones.
5. Head pose estimation to find where the person is looking.
6. Face spoofing detection

# Automated Subjective question Analysis
Automation of the grading can significantly reduce the time and effort required by the human graders, and bring forth other advantages such as disinterested or unbiased checking, efficient and less subjective to human errors. Machine learning models implemented in this project include Bag of words, bag of vectors, bag of centroids, on the manually build datasets from exams given by students enrolled in technical domain courses in Amity University, Noida, India.
